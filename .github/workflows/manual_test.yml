# è§¸ç™¼æ‰‹å‹•æ¸¬è©¦

name: ğŸš€ æ‰‹å‹•åŸ·è¡Œçˆ¬èŸ²æ¸¬è©¦

on:
  workflow_dispatch:
    inputs:
      test_date:
        description: 'æ¸¬è©¦æ—¥æœŸ (YYYY-MM-DD)'
        required: false
        default: '2025-06-11'
        type: string
      debug_mode:
        description: 'å•Ÿç”¨åµéŒ¯æ¨¡å¼'
        required: false
        default: true
        type: boolean

permissions:
  contents: write
  actions: read

jobs:
  run_crawler:
    runs-on: ubuntu-latest
    
    steps:
    - name: æª¢å‡ºä»£ç¢¼
      uses: actions/checkout@v4
      
    - name: è¨­å®š Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: å®‰è£ä¾è³´
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: åŸ·è¡Œçˆ¬èŸ²æ¸¬è©¦
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        MODEL_NAME: ${{ vars.MODEL_NAME || 'gemini-2.0-flash-exp' }}
        LANGUAGE: ${{ vars.LANGUAGE || 'Traditional Chinese' }}
        CUSTOM_DATE: ${{ github.event.inputs.test_date }}
        FORCE_UPDATE: true
      run: |
        echo "é–‹å§‹æ¸¬è©¦çˆ¬èŸ²..."
        echo "æ¸¬è©¦æ—¥æœŸ: ${{ github.event.inputs.test_date }}"
        echo "åµéŒ¯æ¨¡å¼: ${{ github.event.inputs.debug_mode }}"
        
        if [ "${{ github.event.inputs.debug_mode }}" = "true" ]; then
          echo "å•Ÿç”¨åµéŒ¯æ¨¡å¼ï¼Œæ¸¬è©¦ Scrapy ç³»çµ±..."
          cd daily_arxiv
          scrapy crawl arxiv -s CLOSESPIDER_ITEMCOUNT=5
        else
          echo "åŸ·è¡Œå®Œæ•´æµç¨‹..."
          bash run.sh
        fi
        
    - name: æª¢æŸ¥çµæœ
      run: |
        echo "æª¢æŸ¥ç”Ÿæˆçš„æª”æ¡ˆ..."
        ls -la data/ 2>/dev/null || echo "æ²’æœ‰ data ç›®éŒ„"
        
        if [ -f "data/${{ github.event.inputs.test_date }}.jsonl" ]; then
          echo "âœ… åŸå§‹æ•¸æ“šå·²ç”Ÿæˆ"
          echo "æ•¸æ“šå¤§å°: $(wc -c < data/${{ github.event.inputs.test_date }}.jsonl) å­—ç¯€"
        else
          echo "âŒ åŸå§‹æ•¸æ“šæœªç”Ÿæˆ"
        fi