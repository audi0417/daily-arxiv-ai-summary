# 觸發手動測試

name: 🚀 手動執行爬蟲測試

on:
  workflow_dispatch:
    inputs:
      test_date:
        description: '測試日期 (YYYY-MM-DD)'
        required: false
        default: '2025-06-11'
        type: string
      debug_mode:
        description: '啟用偵錯模式'
        required: false
        default: true
        type: boolean

permissions:
  contents: write
  actions: read

jobs:
  run_crawler:
    runs-on: ubuntu-latest
    
    steps:
    - name: 檢出代碼
      uses: actions/checkout@v4
      
    - name: 設定 Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'
        
    - name: 安裝依賴
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: 執行爬蟲測試
      env:
        GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
        MODEL_NAME: ${{ vars.MODEL_NAME || 'gemini-2.0-flash-exp' }}
        LANGUAGE: ${{ vars.LANGUAGE || 'Traditional Chinese' }}
        CUSTOM_DATE: ${{ github.event.inputs.test_date }}
        FORCE_UPDATE: true
      run: |
        echo "開始測試爬蟲..."
        echo "測試日期: ${{ github.event.inputs.test_date }}"
        echo "偵錯模式: ${{ github.event.inputs.debug_mode }}"
        
        if [ "${{ github.event.inputs.debug_mode }}" = "true" ]; then
          echo "啟用偵錯模式，測試 Scrapy 系統..."
          cd daily_arxiv
          scrapy crawl arxiv -s CLOSESPIDER_ITEMCOUNT=5
        else
          echo "執行完整流程..."
          bash run.sh
        fi
        
    - name: 檢查結果
      run: |
        echo "檢查生成的檔案..."
        ls -la data/ 2>/dev/null || echo "沒有 data 目錄"
        
        if [ -f "data/${{ github.event.inputs.test_date }}.jsonl" ]; then
          echo "✅ 原始數據已生成"
          echo "數據大小: $(wc -c < data/${{ github.event.inputs.test_date }}.jsonl) 字節"
        else
          echo "❌ 原始數據未生成"
        fi