#!/usr/bin/env python3
"""
æ¯æ—¥ ArXiv è«–æ–‡æ™ºæ…§æ‘˜è¦ - ä¸»è¦åŸ·è¡Œè…³æœ¬
è‡ªå‹•æŠ“å–ã€è™•ç†ä¸¦ç”Ÿæˆè«–æ–‡æ‘˜è¦å ±å‘Š
"""

import os
import sys
import logging
import yaml
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Optional

# æ–°å¢å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# ä¿®æ­£å°å…¥è·¯å¾‘ - ä½¿ç”¨ç›¸å°å°å…¥
try:
    from crawler.arxiv_crawler import ArxivCrawler
    from processor.data_processor import DataProcessor
    from ai.gemini_enhancer import GeminiEnhancer
    from generator.report_generator import ReportGenerator
    from utils.config_loader import ConfigLoader
    from utils.logger import setup_logger
except ImportError:
    # å¦‚æœç›¸å°å°å…¥å¤±æ•—ï¼Œå˜—è©¦çµ•å°å°å…¥
    sys.path.append(str(project_root / "src"))
    from crawler.arxiv_crawler import ArxivCrawler
    from processor.data_processor import DataProcessor
    from ai.gemini_enhancer import GeminiEnhancer
    from generator.report_generator import ReportGenerator
    from utils.config_loader import ConfigLoader
    from utils.logger import setup_logger


class DailyArxivUpdater:
    """æ¯æ—¥ ArXiv æ›´æ–°å™¨ä¸»é¡åˆ¥"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ›´æ–°å™¨"""
        self.logger = setup_logger("DailyArxivUpdater")
        self.config = ConfigLoader()
        
        # è¼‰å…¥ä¸»é¡Œè¨­å®š
        self.topics_config = self._load_topics_config()
        
        # åˆå§‹åŒ–å„å€‹æ¨¡çµ„
        self.crawler = ArxivCrawler(self.topics_config)
        self.processor = DataProcessor()
        self.ai_enhancer = GeminiEnhancer()
        self.report_generator = ReportGenerator()
        
        # è¨­å®šè³‡æ–™ç›®éŒ„
        self.data_dir = project_root / "data"
        self.data_dir.mkdir(exist_ok=True)
        
    def _load_topics_config(self) -> Dict:
        """è¼‰å…¥ä¸»é¡Œè¨­å®šæª”"""
        config_path = project_root / "config" / "topics.yaml"
        
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            self.logger.info(f"âœ… æˆåŠŸè¼‰å…¥ä¸»é¡Œè¨­å®š: {len(config.get('categories', []))} å€‹é¡åˆ¥")
            return config
        except FileNotFoundError:
            self.logger.error(f"âŒ æ‰¾ä¸åˆ°ä¸»é¡Œè¨­å®šæª”: {config_path}")
            # å›å‚³é è¨­è¨­å®š
            return {
                'categories': ['cs.AI', 'cs.LG'],
                'keywords': {'include': [], 'exclude': []},
                'limits': {'max_papers_per_day': 50}
            }
        except yaml.YAMLError as e:
            self.logger.error(f"âŒ ä¸»é¡Œè¨­å®šæª”æ ¼å¼éŒ¯èª¤: {e}")
            sys.exit(1)
    
    def _get_target_date(self) -> str:
        """å–å¾—ç›®æ¨™æ—¥æœŸ"""
        # æª¢æŸ¥æ˜¯å¦æœ‰è‡ªè¨‚æ—¥æœŸ
        custom_date = os.getenv('CUSTOM_DATE', '').strip()
        if custom_date:
            try:
                # é©—è­‰æ—¥æœŸæ ¼å¼
                datetime.strptime(custom_date, '%Y-%m-%d')
                self.logger.info(f"ğŸ“… ä½¿ç”¨è‡ªè¨‚æ—¥æœŸ: {custom_date}")
                return custom_date
            except ValueError:
                self.logger.warning(f"âš ï¸ è‡ªè¨‚æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œä½¿ç”¨ä»Šæ—¥æ—¥æœŸ: {custom_date}")
        
        # ä½¿ç”¨å°ç£æ™‚å€çš„ä»Šæ—¥æ—¥æœŸ
        try:
            from zoneinfo import ZoneInfo
            taipei_tz = ZoneInfo("Asia/Taipei")
        except ImportError:
            # fallback for older Python versions
            import pytz
            taipei_tz = pytz.timezone("Asia/Taipei")
        
        today = datetime.now(taipei_tz).strftime('%Y-%m-%d')
        self.logger.info(f"ğŸ“… ä½¿ç”¨ä»Šæ—¥æ—¥æœŸ: {today}")
        return today
    
    def _get_previous_days_files(self, target_date: str) -> List[Path]:
        """å–å¾—å‰å¹¾å¤©çš„è³‡æ–™æª”æ¡ˆè·¯å¾‘"""
        target_dt = datetime.strptime(target_date, '%Y-%m-%d')
        previous_files = []
        
        # æª¢æŸ¥å‰ 3 å¤©çš„æª”æ¡ˆ
        for i in range(1, 4):
            prev_date = (target_dt - timedelta(days=i)).strftime('%Y-%m-%d')
            prev_file = self.data_dir / f"{prev_date}_unique.jsonl"
            if prev_file.exists():
                previous_files.append(prev_file)
                
        self.logger.info(f"ğŸ“‚ æ‰¾åˆ° {len(previous_files)} å€‹æ­·å²æª”æ¡ˆç”¨æ–¼å»é‡")
        return previous_files
    
    def run(self) -> bool:
        """åŸ·è¡Œå®Œæ•´çš„æ›´æ–°æµç¨‹"""
        try:
            self.logger.info("ğŸš€ é–‹å§‹æ¯æ—¥ ArXiv è«–æ–‡æ›´æ–°æµç¨‹")
            
            # 1. ç¢ºå®šç›®æ¨™æ—¥æœŸ
            target_date = self._get_target_date()
            
            # 2. å®šç¾©æª”æ¡ˆè·¯å¾‘
            raw_file = self.data_dir / f"{target_date}.jsonl"
            unique_file = self.data_dir / f"{target_date}_unique.jsonl"
            new_only_file = self.data_dir / f"{target_date}_new_only.jsonl"
            enhanced_file = self.data_dir / f"{target_date}_new_only_AI_enhanced.jsonl"
            report_file = self.data_dir / f"{target_date}.md"
            
            # 3. çˆ¬å–è«–æ–‡è³‡æ–™
            self.logger.info("ğŸ“Š æ­¥é©Ÿ 1: çˆ¬å–è«–æ–‡è³‡æ–™")
            papers = self.crawler.crawl_papers(target_date)
            if not papers:
                self.logger.warning("âš ï¸ æ²’æœ‰çˆ¬å–åˆ°ä»»ä½•è«–æ–‡")
                return False
                
            # å„²å­˜åŸå§‹è³‡æ–™
            self.processor.save_papers(papers, raw_file)
            self.logger.info(f"ğŸ’¾ å„²å­˜äº† {len(papers)} ç¯‡è«–æ–‡åˆ° {raw_file}")
            
            # 4. å»é™¤é‡è¤‡
            self.logger.info("ğŸ”„ æ­¥é©Ÿ 2: å»é™¤é‡è¤‡è«–æ–‡")
            unique_papers = self.processor.deduplicate_papers(papers)
            self.processor.save_papers(unique_papers, unique_file)
            self.logger.info(f"âœ¨ å»é‡å¾Œå‰©é¤˜ {len(unique_papers)} ç¯‡è«–æ–‡")
            
            # 5. éæ¿¾æ–°è«–æ–‡
            self.logger.info("ğŸ†• æ­¥é©Ÿ 3: éæ¿¾æ–°è«–æ–‡")
            previous_files = self._get_previous_days_files(target_date)
            new_papers = self.processor.filter_new_papers(unique_papers, previous_files)
            
            # æª¢æŸ¥æ˜¯å¦å¼·åˆ¶æ›´æ–°
            force_update = os.getenv('FORCE_UPDATE', 'false').lower() == 'true'
            
            if not new_papers and not force_update:
                self.logger.info("â„¹ï¸ æ²’æœ‰æ‰¾åˆ°æ–°è«–æ–‡ï¼ŒçµæŸæµç¨‹")
                # æ¸…ç†æš«å­˜æª”æ¡ˆ
                raw_file.unlink(missing_ok=True)
                unique_file.unlink(missing_ok=True)
                return False
                
            if force_update and not new_papers:
                self.logger.info("ğŸ”„ å¼·åˆ¶æ›´æ–°æ¨¡å¼ï¼šä½¿ç”¨æ‰€æœ‰å»é‡å¾Œçš„è«–æ–‡")
                new_papers = unique_papers
                
            self.processor.save_papers(new_papers, new_only_file)
            self.logger.info(f"ğŸ¯ éæ¿¾å‡º {len(new_papers)} ç¯‡æ–°è«–æ–‡")
            
            # 6. AI å¢å¼·è™•ç†
            self.logger.info("ğŸ§  æ­¥é©Ÿ 4: AI å¢å¼·è™•ç†")
            enhanced_papers = self.ai_enhancer.enhance_papers(new_papers)
            if not enhanced_papers:
                self.logger.error("âŒ AI å¢å¼·è™•ç†å¤±æ•—")
                return False
                
            self.processor.save_papers(enhanced_papers, enhanced_file)
            self.logger.info(f"âœ¨ AI å¢å¼·å®Œæˆï¼Œè™•ç†äº† {len(enhanced_papers)} ç¯‡è«–æ–‡")
            
            # 7. ç”Ÿæˆå ±å‘Š
            self.logger.info("ğŸ“ æ­¥é©Ÿ 5: ç”Ÿæˆå ±å‘Š")
            success = self.report_generator.generate_report(
                enhanced_papers, 
                report_file, 
                target_date
            )
            
            if not success:
                self.logger.error("âŒ å ±å‘Šç”Ÿæˆå¤±æ•—")
                return False
                
            # 8. æ›´æ–°ä¸»è¦ README
            self.logger.info("ğŸ“‹ æ­¥é©Ÿ 6: æ›´æ–°ä¸»è¦ README")
            self._update_main_readme()
            
            self.logger.info("ğŸ‰ æ¯æ—¥æ›´æ–°æµç¨‹å®Œæˆï¼")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return False
    
    def _update_main_readme(self):
        """æ›´æ–°ä¸»è¦çš„ README.md æª”æ¡ˆ"""
        try:
            # æƒææ‰€æœ‰ .md å ±å‘Šæª”æ¡ˆ
            md_files = sorted(
                [f for f in self.data_dir.glob("*.md")],
                key=lambda x: x.stem,  # æŒ‰æ—¥æœŸæ’åº
                reverse=True  # æœ€æ–°çš„åœ¨å‰é¢
            )
            
            # è®€å– README ç¯„æœ¬
            template_path = project_root / "templates" / "readme_template.md"
            if not template_path.exists():
                self.logger.warning("âš ï¸ README ç¯„æœ¬æª”æ¡ˆä¸å­˜åœ¨ï¼Œè·³éæ›´æ–°")
                return
                
            with open(template_path, 'r', encoding='utf-8') as f:
                template = f.read()
            
            # ç”Ÿæˆå ±å‘Šé€£çµåˆ—è¡¨
            report_links = []
            for md_file in md_files[:10]:  # åªé¡¯ç¤ºæœ€è¿‘ 10 å€‹å ±å‘Š
                date_str = md_file.stem
                relative_path = f"data/{md_file.name}"
                link = f"- **{date_str}** ğŸ‘‰ [é»æ“ŠæŸ¥çœ‹å ±å‘Š]({relative_path})"
                report_links.append(link)
            
            # å¡«å…¥ç¯„æœ¬
            readme_content = template.format(
                report_list='\n'.join(report_links),
                last_update=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                total_reports=len(md_files)
            )
            
            # å¯«å…¥ä¸»è¦ README
            readme_path = project_root / "README.md"
            with open(readme_path, 'w', encoding='utf-8') as f:
                f.write(readme_content)
                
            self.logger.info("âœ… ä¸»è¦ README.md æ›´æ–°å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ æ›´æ–° README æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")


def main():
    """ä¸»è¦åŸ·è¡Œå‡½æ•¸"""
    try:
        updater = DailyArxivUpdater()
        success = updater.run()
        
        if success:
            print("âœ… æ¯æ—¥æ›´æ–°åŸ·è¡ŒæˆåŠŸ")
            sys.exit(0)
        else:
            print("âš ï¸ æ²’æœ‰æ–°å…§å®¹éœ€è¦æ›´æ–°")
            sys.exit(0)
            
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ä½¿ç”¨è€…ä¸­æ–·åŸ·è¡Œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e}")
        logging.exception("åŸ·è¡Œéç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤")
        sys.exit(1)


if __name__ == "__main__":
    main()