# API åƒè€ƒæ–‡ä»¶

æœ¬æ–‡ä»¶æè¿°äº†å°ˆæ¡ˆä¸­å„å€‹æ¨¡çµ„çš„ API æ¥å£ã€‚

## ğŸ“š æ ¸å¿ƒæ¨¡çµ„

### ArxivCrawler

**è·¯å¾‘**: `src/crawler/arxiv_crawler.py`

#### é¡åˆ¥æè¿°

```python
class ArxivCrawler:
    """ArXiv è«–æ–‡çˆ¬èŸ²é¡åˆ¥"""
```

#### åˆå§‹åŒ–

```python
def __init__(self, config: Dict)
```

**åƒæ•¸**:
- `config` (Dict): é…ç½®å­—å…¸ï¼ŒåŒ…å«é¡åˆ¥ã€é—œéµå­—ç­‰è¨­å®š

#### ä¸»è¦æ–¹æ³•

```python
def crawl_papers(self, target_date: str) -> List[Dict]
```

**åŠŸèƒ½**: çˆ¬å–æŒ‡å®šæ—¥æœŸçš„è«–æ–‡

**åƒæ•¸**:
- `target_date` (str): ç›®æ¨™æ—¥æœŸï¼Œæ ¼å¼ç‚º 'YYYY-MM-DD'

**å›å‚³**: è«–æ–‡è³‡æ–™åˆ—è¡¨

---

### GeminiEnhancer

**è·¯å¾‘**: `src/ai/gemini_enhancer.py`

#### é¡åˆ¥æè¿°

```python
class GeminiEnhancer:
    """Gemini AI å¢å¼·å™¨é¡åˆ¥"""
```

#### ä¸»è¦æ–¹æ³•

```python
def enhance_papers(self, papers: List[Dict]) -> List[Dict]
```

**åŠŸèƒ½**: æ‰¹é‡å¢å¼·è«–æ–‡ï¼ŒåŠ å…¥ AI åˆ†æ

**åƒæ•¸**:
- `papers` (List[Dict]): è«–æ–‡è³‡æ–™åˆ—è¡¨

**å›å‚³**: å¢å¼·å¾Œçš„è«–æ–‡è³‡æ–™åˆ—è¡¨

```python
def enhance_paper(self, paper: Dict) -> Dict
```

**åŠŸèƒ½**: å¢å¼·å–®ç¯‡è«–æ–‡

**åƒæ•¸**:
- `paper` (Dict): å–®ç¯‡è«–æ–‡è³‡æ–™

**å›å‚³**: å¢å¼·å¾Œçš„è«–æ–‡è³‡æ–™

---

### DataProcessor

**è·¯å¾‘**: `src/processor/data_processor.py`

#### ä¸»è¦æ–¹æ³•

```python
def deduplicate_papers(self, papers: List[Dict]) -> List[Dict]
```

**åŠŸèƒ½**: å»é™¤é‡è¤‡è«–æ–‡

```python
def filter_new_papers(self, papers: List[Dict], previous_files: List[Path]) -> List[Dict]
```

**åŠŸèƒ½**: éæ¿¾å‡ºæ–°è«–æ–‡

```python
def save_papers(self, papers: List[Dict], file_path: Path) -> bool
```

**åŠŸèƒ½**: å„²å­˜è«–æ–‡è³‡æ–™åˆ° JSONL æª”æ¡ˆ

```python
def load_papers(self, file_path: Path) -> List[Dict]
```

**åŠŸèƒ½**: å¾ JSONL æª”æ¡ˆè¼‰å…¥è«–æ–‡è³‡æ–™

---

### ReportGenerator

**è·¯å¾‘**: `src/generator/report_generator.py`

#### ä¸»è¦æ–¹æ³•

```python
def generate_report(self, papers: List[Dict], output_file: Path, date: str) -> bool
```

**åŠŸèƒ½**: ç”Ÿæˆ Markdown å ±å‘Š

**åƒæ•¸**:
- `papers` (List[Dict]): è«–æ–‡è³‡æ–™åˆ—è¡¨
- `output_file` (Path): è¼¸å‡ºæª”æ¡ˆè·¯å¾‘
- `date` (str): å ±å‘Šæ—¥æœŸ

**å›å‚³**: æ˜¯å¦æˆåŠŸç”Ÿæˆå ±å‘Š

---

## ğŸ“„ è³‡æ–™çµæ§‹

### è«–æ–‡è³‡æ–™çµæ§‹

```python
{
    'id': str,                    # è«–æ–‡ ID
    'title': str,                 # æ¨™é¡Œ
    'authors': List[str],         # ä½œè€…åˆ—è¡¨
    'summary': str,               # æ‘˜è¦
    'categories': List[str],      # é¡åˆ¥åˆ—è¡¨
    'published': str,             # ç™¼å¸ƒæ—¥æœŸ (ISOæ ¼å¼)
    'updated': str,               # æ›´æ–°æ—¥æœŸ (ISOæ ¼å¼)
    'pdf_url': str,               # PDF é€£çµ
    'entry_id': str,              # ArXiv æ¢ç›® ID
    'primary_category': str,      # ä¸»è¦é¡åˆ¥
    'comment': str,               # è¨»è§£ (å¯é¸)
    'journal_ref': str,           # æœŸåˆŠåƒè€ƒ (å¯é¸)
    'AI': Dict                    # AI å¢å¼·è³‡æ–™ (è¦‹ä¸‹æ–¹)
}
```

### AI å¢å¼·è³‡æ–™çµæ§‹

```python
{
    'tldr': str,                  # ä¸€å¥è©±æ‘˜è¦
    'motivation': str,            # ç ”ç©¶å‹•æ©Ÿ
    'method': str,                # æ–¹æ³•ä»‹ç´¹
    'result': str,                # å¯¦é©—çµæœ
    'conclusion': str,            # ç ”ç©¶çµè«–
    'summary_zh': str,            # ç¹é«”ä¸­æ–‡æ‘˜è¦
    'keywords': List[str],        # é—œéµè©åˆ—è¡¨
    'difficulty': str             # æŠ€è¡“é›£åº¦
}
```

### é…ç½®æª”æ¡ˆçµæ§‹

**config/topics.yaml**:

```yaml
categories:                   # ArXiv é¡åˆ¥åˆ—è¡¨
  - cs.AI
  - cs.LG

keywords:                     # é—œéµå­—éæ¿¾
  include: []                 # åŒ…å«é—œéµå­—
  exclude: []                 # æ’é™¤é—œéµå­—

limits:                       # æ•¸é‡é™åˆ¶
  max_papers_per_day: 50
  max_papers_per_category: 10

date_filter:                  # æ—¥æœŸéæ¿¾
  recent_days: 3
  include_weekends: true

ai_analysis:                  # AI åˆ†æè¨­å®š
  enable_keyword_scoring: true
  enable_related_papers: false
  enable_difficulty_assessment: true

output:                       # è¼¸å‡ºè¨­å®š
  generate_pdf: false
  include_references: false
  detailed_author_info: false
```

---

## ğŸ”§ å·¥å…·å‡½æ•¸

### setup_logger

**è·¯å¾‘**: `src/utils/logger.py`

```python
def setup_logger(name: str, log_file: Optional[Path] = None, level: int = logging.INFO) -> logging.Logger
```

**åŠŸèƒ½**: è¨­å®šçµ±ä¸€çš„æ—¥èªŒè¨˜éŒ„å™¨

### ConfigLoader

**è·¯å¾‘**: `src/utils/config_loader.py`

```python
class ConfigLoader:
    def load_yaml(self, filename: str) -> Dict[str, Any]
    def get_env_config(self) -> Dict[str, str]
    def validate_config(self, config: Dict[str, Any]) -> bool
```

---

## ğŸŒ ç’°å¢ƒè®Šæ•¸

| è®Šæ•¸åç¨± | é¡å‹ | é è¨­å€¼ | èªªæ˜ |
|---------|------|--------|------|
| `GOOGLE_API_KEY` | str | å¿…å¡« | Google Gemini API é‡‘é‘° |
| `MODEL_NAME` | str | `gemini-2.0-flash-exp` | ä½¿ç”¨çš„ AI æ¨¡å‹ |
| `LANGUAGE` | str | `Traditional Chinese` | è¼¸å‡ºèªè¨€ |
| `CUSTOM_DATE` | str | ç©ºå­—ä¸² | è‡ªè¨‚æ—¥æœŸ (YYYY-MM-DD) |
| `FORCE_UPDATE` | str | `false` | æ˜¯å¦å¼·åˆ¶æ›´æ–° |

---

## ğŸ§ª ç¯„ä¾‹ä½¿ç”¨

### åŸºæœ¬ä½¿ç”¨æµç¨‹

```python
from src.crawler.arxiv_crawler import ArxivCrawler
from src.ai.gemini_enhancer import GeminiEnhancer
from src.processor.data_processor import DataProcessor
from src.generator.report_generator import ReportGenerator

# è¼‰å…¥é…ç½®
config = {...}  # å¾ topics.yaml è¼‰å…¥

# åˆå§‹åŒ–æ¨¡çµ„
crawler = ArxivCrawler(config)
enhancer = GeminiEnhancer()
processor = DataProcessor()
generator = ReportGenerator()

# åŸ·è¡Œæµç¨‹
papers = crawler.crawl_papers('2025-06-10')
unique_papers = processor.deduplicate_papers(papers)
enhanced_papers = enhancer.enhance_papers(unique_papers)
success = generator.generate_report(enhanced_papers, 'output.md', '2025-06-10')
```

### è‡ªè¨‚ AI åˆ†æ

```python
from src.ai.gemini_enhancer import GeminiEnhancer

enhancer = GeminiEnhancer()

# ä¿®æ”¹æç¤ºè© (éœ€è¦ç¹¼æ‰¿ä¸¦è¦†å¯« _create_analysis_prompt æ–¹æ³•)
class CustomEnhancer(GeminiEnhancer):
    def _create_analysis_prompt(self, paper):
        # è‡ªè¨‚æç¤ºè©é‚è¼¯
        return custom_prompt
```

é€™ä»½ API åƒè€ƒæ–‡ä»¶æä¾›äº†å°ˆæ¡ˆå„å€‹æ¨¡çµ„çš„è©³ç´°æ¥å£èªªæ˜ï¼Œæ–¹ä¾¿é–‹ç™¼è€…ç†è§£å’Œæ“´å±•åŠŸèƒ½ã€‚